{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "#torchvision contains a collection of datasets for vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b131a13b2e466c9684b500bb4cd6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e7e34bf48f43adbb782282a72c4c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2a26dc4abe42e4bf220fd00450a874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a329172a37d347dda05a282bd64fc787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "#Transform - everything we want to apply to the data\n",
    "#Shuffle - MNIST - hand drawn numbers data set from 0 - 9 28 by 28 image\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch - how many at a time do we want to pass to a model\n",
    "# Nerual network advantage - when we can leverage millions - billions worth of samples\n",
    "# Neurons per layer - trial and error\n",
    "# Graident descent operation\n",
    "# as models start to optimise every weights and bias - if you pass whole data at once,\n",
    "# the machine may learn some generalisation at once, machine might find that some weights are just arbitrary\n",
    "# is this generally trough or is it because this is in sample data - machine has no way to know this\n",
    "# if we pass through batches at a time, each time it optimizes the optimization that stick around generally are going to be the\n",
    "# general the generalizations the correct things that assumed than just fitment cases - erased out when working in batches\n",
    "# not the case when you want a bigger batch size - sweet spot batch sizes ~ usually 8 to 64 regardless how big your memory is\n",
    "\n",
    "#Shuffle - Providing neural network opportunity to learn general principles rather than just simply figuring out tricks\n",
    "# if there is a quickeer route to get to increasing / decreasing loss - NN is going to take that route\n",
    "\n",
    "train_set = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([9, 5, 0, 0, 6, 9, 9, 4, 4, 3])]\n"
     ]
    }
   ],
   "source": [
    "#showing the data. firstly shown the actual data 28 x 28 and then the result in a batch of 10\n",
    "for data in train_set:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "tensor(9)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Data is a tensor object containing list of tensors of images and then list of tensors that are labels\n",
    "x, y = data[0][0], data[1][0]\n",
    "# extra 1 in tensor shape\n",
    "print(x.shape)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "#balancing - if a model can find a shorter path to decrease loss- the optimiser doesn'tknow how good could we get\n",
    "# just trying to decrease loss the best possible\n",
    "# what if 60% of our dataset is #3 - our model is quickly learn and adjust weight such that it will always predict a 3\n",
    "# it is stuck into a hole - getting out means the loss is alot worse than before\n",
    "# make sure data is as balanced as possible\n",
    "# attempt: modifying the weights of specific classes when calculating loss\n",
    "# confirming that the data set is balanced\n",
    "\n",
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in train_set:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
