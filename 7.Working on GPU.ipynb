{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=6gk7giKER6s&list=PLQVvvaa0QuDdeMyHEYc0gxFpYwHY2Qfdh&index=7\n",
    "To run locally\n",
    "Good GPU - above 4GB Vram\n",
    "Cuda Enabled\n",
    "Cuda Tool Kit\n",
    "Cuda NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=1gQR24B3ISE&list=PLQVvvaa0QuDdeMyHEYc0gxFpYwHY2Qfdh&index=6\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#in your pre-processing dataset you dont want to build data everytime you run your code\n",
    "REBUILD_DATA = False\n",
    "\n",
    "class DogsVSCats():\n",
    "    #first, specify the size of the image i.e. 50 by 50\n",
    "    #input images vary in sizes and shape (some are portrait, some are landscape) - we need them to uniform on input\n",
    "    # normalised to the same size\n",
    "    # resizing the images or resize and pad (adding white / black pixels on smaller images with open cv)\n",
    "    #shift over and crop the image, rotate or flip them\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"kagglecatsanddogs_3367a/PetImages/Cat\"\n",
    "    DOGS = \"kagglecatsanddogs_3367a/PetImages/Dog\"\n",
    "    #Pre-labelled data\n",
    "    LABELS ={CATS: 0, DOGS: 1}\n",
    "    # massive list of images with their label\n",
    "    training_data = []\n",
    "    cat_count = 0\n",
    "    dog_count = 0\n",
    "        \n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(\"directory: \",label)\n",
    "            #looping all the images in the directory\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                try:\n",
    "                    path = os.path.join(label,f)\n",
    "                    img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
    "                    if label == self.CATS:\n",
    "                        self.cat_count += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dog_count += 1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    #print(str(e))                    \n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"Cats:\", self.cat_count)\n",
    "        print(\"Dogs:\", self.dog_count)\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 90,  88,  95, ..., 100, 114, 158],\n",
      "       [ 95,  89,  98, ..., 106, 117, 166],\n",
      "       [ 95,  98,  98, ..., 102, 121, 177],\n",
      "       ...,\n",
      "       [ 49,  50,  51, ..., 106, 174, 177],\n",
      "       [ 39,  52,  50, ..., 104, 175, 177],\n",
      "       [ 74,  76,  69, ..., 108, 180, 177]], dtype=uint8)\n",
      " array([1., 0.])]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index = 16\n",
    "plt.imshow(training_data[index][0], cmap= \"gray\")\n",
    "plt.show()\n",
    "print(training_data[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,5)\n",
    "        self.conv2 = nn.Conv2d(32,64,5)\n",
    "        self.conv3 = nn.Conv2d(64,128,5)\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        # self.fc1 = nn.Linear ( ??? , 512)\n",
    "        self.fc1 = nn.Linear(self._to_linear,512)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "    def convs(self, x):\n",
    "        #just like the forward method but only applying to the convolutional layers\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
    "        \n",
    "        #print(x[0].shape)\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "    def forward (self,x):\n",
    "        #required to know the flattened result after initializing during real forward pass\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #returning an activation layer rather than just x\n",
    "        return F.softmax(x, dim = 1)\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# All the parameters in the nn is controlled by the optimiser\n",
    "## moved to bottom\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "#Scaling the imagery - between 0 - 1 from 0 - 255\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "\n",
    "VAL_PCT = 0.1\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X is :  22452 with train_y :  22452\n",
      "test_X is :  2494 with test_y :  2494\n"
     ]
    }
   ],
   "source": [
    "train_X = X[: -val_size]\n",
    "train_y = y[: -val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print(\"train_X is : \",len(train_X), \"with train_y : \", len(train_y))\n",
    "print(\"test_X is : \",len(test_X), \"with test_y : \", len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:00<00:00, 37468.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100\n",
      "100 200\n",
      "200 300\n",
      "300 400\n",
      "400 500\n",
      "500 600\n",
      "600 700\n",
      "700 800\n",
      "800 900\n",
      "900 1000\n",
      "1000 1100\n",
      "1100 1200\n",
      "1200 1300\n",
      "1300 1400\n",
      "1400 1500\n",
      "1500 1600\n",
      "1600 1700\n",
      "1700 1800\n",
      "1800 1900\n",
      "1900 2000\n",
      "2000 2100\n",
      "2100 2200\n",
      "2200 2300\n",
      "2300 2400\n",
      "2400 2500\n",
      "2500 2600\n",
      "2600 2700\n",
      "2700 2800\n",
      "2800 2900\n",
      "2900 3000\n",
      "3000 3100\n",
      "3100 3200\n",
      "3200 3300\n",
      "3300 3400\n",
      "3400 3500\n",
      "3500 3600\n",
      "3600 3700\n",
      "3700 3800\n",
      "3800 3900\n",
      "3900 4000\n",
      "4000 4100\n",
      "4100 4200\n",
      "4200 4300\n",
      "4300 4400\n",
      "4400 4500\n",
      "4500 4600\n",
      "4600 4700\n",
      "4700 4800\n",
      "4800 4900\n",
      "4900 5000\n",
      "5000 5100\n",
      "5100 5200\n",
      "5200 5300\n",
      "5300 5400\n",
      "5400 5500\n",
      "5500 5600\n",
      "5600 5700\n",
      "5700 5800\n",
      "5800 5900\n",
      "5900 6000\n",
      "6000 6100\n",
      "6100 6200\n",
      "6200 6300\n",
      "6300 6400\n",
      "6400 6500\n",
      "6500 6600\n",
      "6600 6700\n",
      "6700 6800\n",
      "6800 6900\n",
      "6900 7000\n",
      "7000 7100\n",
      "7100 7200\n",
      "7200 7300\n",
      "7300 7400\n",
      "7400 7500\n",
      "7500 7600\n",
      "7600 7700\n",
      "7700 7800\n",
      "7800 7900\n",
      "7900 8000\n",
      "8000 8100\n",
      "8100 8200\n",
      "8200 8300\n",
      "8300 8400\n",
      "8400 8500\n",
      "8500 8600\n",
      "8600 8700\n",
      "8700 8800\n",
      "8800 8900\n",
      "8900 9000\n",
      "9000 9100\n",
      "9100 9200\n",
      "9200 9300\n",
      "9300 9400\n",
      "9400 9500\n",
      "9500 9600\n",
      "9600 9700\n",
      "9700 9800\n",
      "9800 9900\n",
      "9900 10000\n",
      "10000 10100\n",
      "10100 10200\n",
      "10200 10300\n",
      "10300 10400\n",
      "10400 10500\n",
      "10500 10600\n",
      "10600 10700\n",
      "10700 10800\n",
      "10800 10900\n",
      "10900 11000\n",
      "11000 11100\n",
      "11100 11200\n",
      "11200 11300\n",
      "11300 11400\n",
      "11400 11500\n",
      "11500 11600\n",
      "11600 11700\n",
      "11700 11800\n",
      "11800 11900\n",
      "11900 12000\n",
      "12000 12100\n",
      "12100 12200\n",
      "12200 12300\n",
      "12300 12400\n",
      "12400 12500\n",
      "12500 12600\n",
      "12600 12700\n",
      "12700 12800\n",
      "12800 12900\n",
      "12900 13000\n",
      "13000 13100\n",
      "13100 13200\n",
      "13200 13300\n",
      "13300 13400\n",
      "13400 13500\n",
      "13500 13600\n",
      "13600 13700\n",
      "13700 13800\n",
      "13800 13900\n",
      "13900 14000\n",
      "14000 14100\n",
      "14100 14200\n",
      "14200 14300\n",
      "14300 14400\n",
      "14400 14500\n",
      "14500 14600\n",
      "14600 14700\n",
      "14700 14800\n",
      "14800 14900\n",
      "14900 15000\n",
      "15000 15100\n",
      "15100 15200\n",
      "15200 15300\n",
      "15300 15400\n",
      "15400 15500\n",
      "15500 15600\n",
      "15600 15700\n",
      "15700 15800\n",
      "15800 15900\n",
      "15900 16000\n",
      "16000 16100\n",
      "16100 16200\n",
      "16200 16300\n",
      "16300 16400\n",
      "16400 16500\n",
      "16500 16600\n",
      "16600 16700\n",
      "16700 16800\n",
      "16800 16900\n",
      "16900 17000\n",
      "17000 17100\n",
      "17100 17200\n",
      "17200 17300\n",
      "17300 17400\n",
      "17400 17500\n",
      "17500 17600\n",
      "17600 17700\n",
      "17700 17800\n",
      "17800 17900\n",
      "17900 18000\n",
      "18000 18100\n",
      "18100 18200\n",
      "18200 18300\n",
      "18300 18400\n",
      "18400 18500\n",
      "18500 18600\n",
      "18600 18700\n",
      "18700 18800\n",
      "18800 18900\n",
      "18900 19000\n",
      "19000 19100\n",
      "19100 19200\n",
      "19200 19300\n",
      "19300 19400\n",
      "19400 19500\n",
      "19500 19600\n",
      "19600 19700\n",
      "19700 19800\n",
      "19800 19900\n",
      "19900 20000\n",
      "20000 20100\n",
      "20100 20200\n",
      "20200 20300\n",
      "20300 20400\n",
      "20400 20500\n",
      "20500 20600\n",
      "20600 20700\n",
      "20700 20800\n",
      "20800 20900\n",
      "20900 21000\n",
      "21000 21100\n",
      "21100 21200\n",
      "21200 21300\n",
      "21300 21400\n",
      "21400 21500\n",
      "21500 21600\n",
      "21600 21700\n",
      "21700 21800\n",
      "21800 21900\n",
      "21900 22000\n",
      "22000 22100\n",
      "22100 22200\n",
      "22200 22300\n",
      "22300 22400\n",
      "22400 22500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "#Slices of our data\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "        print(i, i + BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:27<00:00,  8.12it/s]\n",
      "  0%|          | 1/225 [00:00<00:26,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.25281524658203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:27<00:00,  8.19it/s]\n",
      "  0%|          | 1/225 [00:00<00:27,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Loss: 0.2484213411808014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:27<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2. Loss: 0.1945650577545166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 3\n",
    "#Slices of our data\n",
    "def train(net):\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "            net.zero_grad()\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "\n",
    "train(net)\n",
    "# Do the fitment optimisation - zero the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [00:03<00:00, 678.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test(net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            real_class = torch.argmax(test_y[i])\n",
    "            net_out = net(test_X[i].view(-1,1,50,50))[0]\n",
    "\n",
    "            #print(real_class, net_out)\n",
    "            predicted_class = torch.argmax(net_out)\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    print(\"Accuracy: \", round (correct/total,3))\n",
    "test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start of GPU implementation\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on the GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes our entire neural network and pops it up on to our GPU\n",
    "#cannot default pytorch to GPU because alot of transactions between CPU and GPU \n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the nerual network on the device\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 105.09it/s]\n",
      "  5%|▍         | 11/225 [00:00<00:02, 104.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.17151504755020142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 107.47it/s]\n",
      "  5%|▌         | 12/225 [00:00<00:01, 111.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Loss: 0.07996553927659988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 107.37it/s]\n",
      "  5%|▌         | 12/225 [00:00<00:01, 111.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2. Loss: 0.1291702687740326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 107.60it/s]\n",
      " 10%|▉         | 22/225 [00:00<00:01, 109.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3. Loss: 0.10065232217311859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 105.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4. Loss: 0.06606099754571915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Not practical to put all the data on the GPU\n",
    "#If you can have all the data on GPU -> do it\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 5\n",
    "\n",
    "def train_gpu(net):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    loss_function = nn.MSELoss()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            net.zero_grad()\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "train_gpu(net)\n",
    "\n",
    "        # Do the fitment optimisation - zero the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [00:03<00:00, 694.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_gpu(net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            real_class = torch.argmax(test_y[i]).to(device)\n",
    "            net_out = net(test_X[i].view(-1,1,50,50).to(device))[0]\n",
    "\n",
    "            #print(real_class, net_out)\n",
    "            predicted_class = torch.argmax(net_out)\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    print(\"Accuracy: \", round (correct/total,3))\n",
    "test_gpu(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 106.67it/s]\n",
      "  5%|▌         | 12/225 [00:00<00:01, 111.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 0.06726612895727158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 107.74it/s]\n",
      "  5%|▌         | 12/225 [00:00<00:01, 111.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Loss: 0.06390628963708878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 108.93it/s]\n",
      "  5%|▌         | 12/225 [00:00<00:01, 111.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2. Loss: 0.06745751202106476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 107.69it/s]\n",
      "  5%|▌         | 12/225 [00:00<00:01, 112.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3. Loss: 0.040335386991500854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:02<00:00, 108.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4. Loss: 0.02338463068008423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Increase accuracy by - increasing EPOCH\n",
    "# train again\n",
    "train_gpu(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2494/2494 [00:03<00:00, 699.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_gpu(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
